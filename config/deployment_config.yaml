# Deployment configuration for powerful machines deployment: # Model training settings for powerful hardware heavy_training: epochs: 500 batch_size: 32 # Larger batch for RTX GPUs sequence_length: 150 # Longer sequences learning_rate: 0.001 early_stopping_patience: 50 # GPU optimization settings gpu_settings: memory_growth: true mixed_precision: true # For RTX series use_cuda: true # Data settings data_collection: years: 10 # 10 years of data symbols_count: 50 # More symbols features_count: 200 # More features # Hardware specific settings rtx_1080: recommended_batch_size: 32 max_sequence_length: 200 estimated_time_per_epoch: "4-6 minutes" total_estimated_time: "30-50 hours" i7_13th_gen: cpu_cores: 16 recommended_workers: 8 data_preprocessing_time: "2-4 hours" # Training resume settings resume: auto_resume: true checkpoint_frequency: 10 # Save every 10 epochs backup_location: "models/checkpoints/"