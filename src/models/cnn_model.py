""" CNN model implementation for market prediction. """ import tensorflow as tf from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dense, Dropout, Flatten, BatchNormalization from tensorflow.keras.optimizers import Adam from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint import numpy as np from typing import Dict, Tuple, Optional, List from loguru import logger class CNNModel: """CNN model for time series prediction.""" def __init__(self, config: Dict): """ Initialize CNN model with configuration. Args: config: Model configuration dictionary """ self.config = config self.model = None self.history = None def build_model(self, input_shape: Tuple[int, int], output_dim: int = 1) -> tf.keras.Model: """ Build CNN model architecture. Args: input_shape: Shape of input data (sequence_length, features) output_dim: Output dimension Returns: Compiled Keras model """ try: model = Sequential() # Get configuration filters = self.config.get('filters', [32, 64, 128]) kernel_sizes = self.config.get('kernel_sizes', [3, 3, 3]) pool_size = self.config.get('pool_size', 2) dropout = self.config.get('dropout', 0.25) # Ensure lists have the same length min_length = min(len(filters), len(kernel_sizes)) filters = filters[:min_length] kernel_sizes = kernel_sizes[:min_length] # First convolutional layer model.add(Conv1D( filters=filters[0], kernel_size=kernel_sizes[0], activation='relu', input_shape=input_shape, padding='same' )) model.add(BatchNormalization()) model.add(MaxPooling1D(pool_size=pool_size)) model.add(Dropout(dropout)) # Additional convolutional layers for i in range(1, len(filters)): model.add(Conv1D( filters=filters[i], kernel_size=kernel_sizes[i], activation='relu', padding='same' )) model.add(BatchNormalization()) model.add(MaxPooling1D(pool_size=pool_size)) model.add(Dropout(dropout)) # Flatten and dense layers model.add(Flatten()) model.add(Dense(100, activation='relu')) model.add(Dropout(dropout)) model.add(Dense(50, activation='relu')) model.add(Dropout(dropout)) model.add(Dense(output_dim, activation='linear')) # Compile model optimizer = Adam(learning_rate=self.config.get('learning_rate', 0.001)) model.compile( optimizer=optimizer, loss='mse', metrics=['mae', 'mape'] ) self.model = model logger.info(f"CNN model built with input shape: {input_shape}") return model except Exception as e: logger.error(f"Error building CNN model: {e}") return None def train(self, X_train: np.ndarray, y_train: np.ndarray, X_val: Optional[np.ndarray] = None, y_val: Optional[np.ndarray] = None, epochs: int = 100, batch_size: int = 32) -> Dict: """ Train the CNN model. """ try: if self.model is None: logger.error("Model not built. Call build_model() first.") return {} # Prepare validation data validation_data = None if X_val is not None and y_val is not None: validation_data = (X_val, y_val) # Define callbacks callbacks = [ EarlyStopping( monitor='val_loss' if validation_data else 'loss', patience=10, restore_best_weights=True, verbose=1 ), ReduceLROnPlateau( monitor='val_loss' if validation_data else 'loss', factor=0.5, patience=5, min_lr=1e-7, verbose=1 ), ModelCheckpoint( 'models/best_cnn_model.h5', monitor='val_loss' if validation_data else 'loss', save_best_only=True, verbose=1 ) ] # Train model history = self.model.fit( X_train, y_train, validation_data=validation_data, epochs=epochs, batch_size=batch_size, callbacks=callbacks, verbose=1 ) self.history = history logger.info("CNN model training completed") return history.history except Exception as e: logger.error(f"Error training CNN model: {e}") return {} def predict(self, X: np.ndarray) -> np.ndarray: """Make predictions with the trained model.""" try: if self.model is None: logger.error("Model not trained. Call train() first.") return np.array([]) predictions = self.model.predict(X, verbose=0) logger.info(f"Generated predictions for {len(X)} samples") return predictions.flatten() except Exception as e: logger.error(f"Error making predictions: {e}") return np.array([]) def evaluate(self, X_test: np.ndarray, y_test: np.ndarray) -> Dict: """Evaluate model performance.""" try: if self.model is None: logger.error("Model not trained. Call train() first.") return {} # Get predictions predictions = self.predict(X_test) # Calculate metrics mse = np.mean((y_test - predictions) ** 2) mae = np.mean(np.abs(y_test - predictions)) rmse = np.sqrt(mse) mape = np.mean(np.abs((y_test - predictions) / y_test)) * 100 # Directional accuracy actual_direction = np.sign(np.diff(y_test)) predicted_direction = np.sign(np.diff(predictions)) directional_accuracy = np.mean(actual_direction == predicted_direction) * 100 metrics = { 'mse': float(mse), 'mae': float(mae), 'rmse': float(rmse), 'mape': float(mape), 'directional_accuracy': float(directional_accuracy) } logger.info(f"Model evaluation completed: RMSE={rmse:.4f}, MAE={mae:.4f}") return metrics except Exception as e: logger.error(f"Error evaluating model: {e}") return {} def save_model(self, filepath: str): """Save the trained model.""" try: if self.model is None: logger.error("No model to save") return self.model.save(filepath) logger.info(f"Model saved to {filepath}") except Exception as e: logger.error(f"Error saving model: {e}") def load_model(self, filepath: str): """Load a trained model.""" try: self.model = tf.keras.models.load_model(filepath) logger.info(f"Model loaded from {filepath}") except Exception as e: logger.error(f"Error loading model: {e}")